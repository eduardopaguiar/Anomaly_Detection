{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ADP\n",
    "import data_manipulation as dm\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiation Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ##########################################################\n",
    "    # ------------------------------------------------------ #\n",
    "    # --------------------- INITIATION --------------------- #\n",
    "    # ------------------------------------------------------ #\n",
    "    ##########################################################\n",
    "    ### Define User Variables ###\n",
    "\n",
    "    # List of Granularities\n",
    "    gra_list = [i for i in range(1,11)]\n",
    "\n",
    "    # Number of Iterations\n",
    "    iterations = 33\n",
    "\n",
    "    # Number of events\n",
    "    total = 100000\n",
    "\n",
    "    # Number of Data-set divisions\n",
    "    windows = 100\n",
    "\n",
    "    # Percentage of background samples on the testing phase\n",
    "    background_percent = 0.99\n",
    "\n",
    "    # Percentage of samples on the training phase\n",
    "    test_size = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    ##########################################################\n",
    "    # ------------------------------------------------------ #\n",
    "    # ----------------------- LOADING ---------------------- #\n",
    "    # ------------------------------------------------------ #\n",
    "    ##########################################################\n",
    "    # Firstly the model loads the background and signal data, \n",
    "    # then it removes the attributes first string line, which \n",
    "    # are the column names, in order to avoid NaN values in \n",
    "    # the array.\n",
    "\n",
    "    print('         ==== Commencing Initiation ====\\n')\n",
    "\n",
    "    ### Background    \n",
    "    b_name='Input_Background_1.csv'\n",
    "    background = np.genfromtxt(b_name, delimiter=',')\n",
    "    background = background[1:,:]\n",
    "    Lb, W = background.shape\n",
    "    print(\"     .Background Loaded...\" )\n",
    "    print(\"     .Background shape: {}\".format(background.shape))\n",
    "\n",
    "    ### Signal\n",
    "    s_name='Input_Signal_1.csv'\n",
    "    signal = np.genfromtxt(s_name, delimiter=',')\n",
    "    signal = signal[1:,:]\n",
    "    Ls, _ = signal.shape\n",
    "    print(\"     .Signal Loaded...\")\n",
    "    print(\"     .Signal shape: {}\\n\".format(signal.shape))\n",
    "\n",
    "    print('\\n          ==== Initiation Complete ====\\n')\n",
    "    print('=*='*17 )\n",
    "    print('      ==== Commencing Data Processing ====')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    threshold_list = []\n",
    "    f, ax = plt.subplots(2,21,figsize=(21*16,2*7))\n",
    "    for n_i in range(iterations):\n",
    "        t_dict = {}\n",
    "        \n",
    "        ##########################################################\n",
    "        # ------------------------------------------------------ #\n",
    "        # ------------------- Preparing Data ------------------- #\n",
    "        # ------------------------------------------------------ #\n",
    "        ##########################################################\n",
    "        print('\\n     => Iteration Number', (n_i+1) )\n",
    "        \n",
    "        # Divide data-set\n",
    "        b_samples = int(total*background_percent)\n",
    "        s_samples = total - b_samples\n",
    "        \n",
    "        print('         .Dividing background and signal sub-sets')\n",
    "        _, divided_background = train_test_split(background, test_size=b_samples/Lb)\n",
    "        _, divided_signal = train_test_split(signal, test_size=s_samples/Ls)\n",
    "\n",
    "        print('         .Selecting Signal on the following porpotion:')\n",
    "        print('             .{}% Background samples'.format(int(background_percent*100)))\n",
    "        print('             .{}% Signal samples'.format(int((1-background_percent)*100)))\n",
    "        print('             .{:9d} of Background samples'.format(int(b_samples)) )\n",
    "        print('             .{:9d} of Signal samples)'.format(int(s_samples)))\n",
    "\n",
    "        # Concatenating Signal and the Test Background sub-set\n",
    "        streaming_data_raw = np.concatenate((divided_background,divided_signal), axis=0)\n",
    "        print(\"             .FullData shape: {}\\n\".format(streaming_data_raw.shape))\n",
    "\n",
    "        # Normalize Data\n",
    "        print('         .Normalizing Data')\n",
    "        streaming = normalize(streaming_data_raw,norm='max',axis=0)\n",
    "        \n",
    "        columns = ['px1','py1','pz1','E1','eta1','phi1','pt1',\n",
    "           'px2','py2','pz2','E2','eta2','phi2','pt2',\n",
    "           'Delta_R','M12','MET','S','C','HT','A']\n",
    "        \n",
    "        for i in range(21):\n",
    "            density = gaussian_kde(streaming[:b_samples,i])\n",
    "            xs = np.linspace(-1,1,200)\n",
    "            density.covariance_factor = lambda : .25\n",
    "            density._compute_covariance()\n",
    "            ax[0,i].set_title('{} - Background'.format(columns[i]), fontsize=15)\n",
    "            ax[0,i].fill_between(xs,density(xs), color='tab:blue', alpha=.2)\n",
    "            \n",
    "            density = gaussian_kde(streaming[b_samples:,i])\n",
    "            xs = np.linspace(-1,1,200)\n",
    "            density.covariance_factor = lambda : .25\n",
    "            density._compute_covariance()\n",
    "            ax[1,i].set_title('{} - Signal'.format(columns[i]), fontsize=15)\n",
    "            ax[1,i].fill_between(xs,density(xs), color='tab:blue', alpha=.2)\n",
    "    \n",
    "    plt.savefig('dist.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "            \n",
    "\n",
    "            \n",
    "            #f = plt.figure(figsize=(16,7))\n",
    "            #plt.title('{} Background - {} Signal'.format(L1, L2))\n",
    "            #sns.set(font_scale=1.5)\n",
    "            #sns.kdeplot(data=total_df, x=x, hue='label',\n",
    "            #            fill=True,common_norm=False, palette=\"tab10\",alpha=.5, linewidth=0)\n",
    "            #fig_list.append(f)\n",
    "            #plt.show()\n",
    "        \n",
    "        \n",
    "        #pdf = matplotlib.backends.backend_pdf.PdfPages(\"pdf_atributes.pdf\")\n",
    "        #for fig in fig_list:\n",
    "        #    pdf.savefig(fig)\n",
    "        #pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
